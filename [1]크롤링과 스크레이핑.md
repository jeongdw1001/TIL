## 1_urllib_실습



```python
import urllib.request as req
```


```python
# 파일 URL
img_url = "http://post.phinf.naver.net/20160621_169/1466482468068lmSHj_JPEG/If7GeIbOPZuYwI-GI3xU7ENRrlfI.jpg"
html_url = "http://google.com"
```


```python
# 다운받을 경로
save_path1 = "C:/Myexam/test1.jpg"
save_path2 = "C:/Myexam/index.html"
```


```python
# 예외 처리
try:
    file1, header1 = req.urlretrieve(img_url, save_path1)
    file2, header2 = req.urlretrieve(html_url, save_path2)
except Exception as e:
    print("Download failed.")
    print(e)
else:
    # Header 정보 출력
    print(header1)
    print(header2)
```

<pre>
Date: Tue, 17 Jan 2023 16:26:56 GMT
Accept-Ranges: bytes
Cache-Control: max-age=15552000
Content-Length: 797094
Content-Type: image/jpeg
Last-Modified: Tue, 17 Jan 2023 06:29:50 GMT
p3p: CP="ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC"
Age: 35826
Expires: Sun, 16 Jul 2023 06:29:50 GMT
Connection: close


Date: Tue, 17 Jan 2023 16:26:55 GMT
Expires: -1
Cache-Control: private, max-age=0
Content-Type: text/html; charset=ISO-8859-1
Cross-Origin-Opener-Policy-Report-Only: same-origin-allow-popups; report-to="gws"
Report-To: {"group":"gws","max_age":2592000,"endpoints":[{"url":"https://csp.withgoogle.com/csp/report-to/gws/other"}]}
P3P: CP="This is not a P3P policy! See g.co/p3phelp for more info."
Server: gws
X-XSS-Protection: 0
X-Frame-Options: SAMEORIGIN
Set-Cookie: 1P_JAR=2023-01-17-16; expires=Thu, 16-Feb-2023 16:26:56 GMT; path=/; domain=.google.com; Secure
Set-Cookie: AEC=ARSKqsLq8pCoX2CjtySIYkPIMw9o65Cx91diLOek1Zmk1cqi9AxzgeNqVQ; expires=Sun, 16-Jul-2023 16:26:56 GMT; path=/; domain=.google.com; Secure; HttpOnly; SameSite=lax
Set-Cookie: NID=511=E3-6tA5i6u8VBs8Gk6zlvvAlnlGE3pAP-1xQJLfjrhEtJjgfoIdvALM1xITkj3EANyIvd3qkngVK-i54aTM7Mzo2d2EjBzIW5NyoSUnSBNyRPE2_WU52PD5yDyvnljigcw_2LEaMUVoUi86y5FxNKaM0VzAuv71Tj4Z8c524k0U; expires=Wed, 19-Jul-2023 16:26:55 GMT; path=/; domain=.google.com; HttpOnly
Accept-Ranges: none
Vary: Accept-Encoding
Connection: close
Transfer-Encoding: chunked


</pre>

```python
#다운로드 파일 정보
print("Filename1 {}".format(file1))
print("Filename2 {}".format(file2))
print()
```

<pre>
Filename1 C:/Myexam/test1.jpg
Filename2 C:/Myexam/index.html

</pre>

```python
#성공
print("Download Succeed.")
```

<pre>
Download Succeed.
</pre>
## 2. urlopen_실습

### urlopen 함수 기초 사용법




```python
import urllib.request as req
from urllib.error import URLError, HTTPError
```


```python
# 다운로드 경로 및 파일명
path_list = ["C:/Myexam/test1.jpg","C:/Myexam/index.html"]
```


```python
# 다운로드 리소스 URL
target_url = [ "http://post.phinf.naver.net/20160621_169/1466482468068lmSHj_JPEG/If7GeIbOPZuYwI-GI3xU7ENRrlfI.jpg",
                "http://google.com"]
```


```python
for i, url in enumerate(target_url):
    #예외 처리
    try:
        #웹 수신 정보 읽기
        response = req.urlopen(url)
        #수신 내용
        contents = response.read()
        print('-'*30)
        #상태 정보 중간 출력
        print('Header Info-{} : {}'.format(i, response.info()))
        print('HTTP Status Code : {}'.format(response.getcode()))
        print()
        print('-'*30)
        #파일쓰기
        with open(path_list[i], 'wb') as c:
            c.write(contents)
        #HTTP 에러 발생 시
    except HTTPError as e:
        print("Download failed.")
        print("HTTP Error Code : ", e.code)
        #URL 에러 발생 시
    except URLError as e:
        print("Download failed.")
        print("URL Error Reason : ", e.reason) 
        #성공
    else:
        print()
        print("Download Succeed")
        
```

<pre>
------------------------------
Header Info-0 : Date: Tue, 17 Jan 2023 16:26:55 GMT
Accept-Ranges: bytes
Cache-Control: max-age=15552000
Content-Length: 797094
Content-Type: image/jpeg
Last-Modified: Tue, 17 Jan 2023 06:15:28 GMT
p3p: CP="ALL CURa ADMa DEVa TAIa OUR BUS IND PHY ONL UNI PUR FIN COM NAV INT DEM CNT STA POL HEA PRE LOC OTC"
Age: 36688
Expires: Sun, 16 Jul 2023 06:15:28 GMT
Connection: close


HTTP Status Code : 200

------------------------------

Download Succeed
------------------------------
Header Info-1 : Date: Tue, 17 Jan 2023 16:26:56 GMT
Expires: -1
Cache-Control: private, max-age=0
Content-Type: text/html; charset=ISO-8859-1
Cross-Origin-Opener-Policy-Report-Only: same-origin-allow-popups; report-to="gws"
Report-To: {"group":"gws","max_age":2592000,"endpoints":[{"url":"https://csp.withgoogle.com/csp/report-to/gws/other"}]}
P3P: CP="This is not a P3P policy! See g.co/p3phelp for more info."
Server: gws
X-XSS-Protection: 0
X-Frame-Options: SAMEORIGIN
Set-Cookie: 1P_JAR=2023-01-17-16; expires=Thu, 16-Feb-2023 16:26:56 GMT; path=/; domain=.google.com; Secure
Set-Cookie: AEC=ARSKqsIhOTxFYDgIxXtWwh7SMX6Wa-lGB_72G6gJ6iI5Yggblz0_SsoZtlo; expires=Sun, 16-Jul-2023 16:26:56 GMT; path=/; domain=.google.com; Secure; HttpOnly; SameSite=lax
Set-Cookie: NID=511=YoKyJnaFIiZ2g_RMiM_lkSjUYGIzUrcAK9ZMtD6XuvkEnUw0oebfotg9IwHjtDUO0SWhybvoGZu3CSlRdRoAnUWurV7X0VIdF75CX3hSHA5MFKFEydmsq_jJnWuTYYc7derJa3PvBMFWp8USStuj_vGNcp1eax5QOHNBfisKNvA; expires=Wed, 19-Jul-2023 16:26:56 GMT; path=/; domain=.google.com; HttpOnly
Accept-Ranges: none
Vary: Accept-Encoding
Connection: close
Transfer-Encoding: chunked


HTTP Status Code : 200

------------------------------

Download Succeed
</pre>
## 3. lxml_실습

### lxml 사용 기초 스크랩핑(1)



```python
#pip install lxml을 윈도우 cmd 창에서 실행한다.
#pip install requests
#pip install cssselect
```


```python
from typing import get_args
import requests
from lxml.html import fromstring, tostring
```


```python
def main():
    """
    네이버 지식인 스크랩핑 메인 함수
    """
    
    # 세션 사용
    session = requests.Session()
    # 스크랩핑 대상 url (get/post)
    response = session.get("https://kin.naver.com/search/list.nhn?query=%ED%8C%8C%EC%9D%B4%EC%8D%AC")
    # 신문사 링크 리스트 획득
    urls = scrape_news_list_page(response)
    
    # 딕셔너리 확인
    #print(urls)
    
    for name, url in urls.items():
        print(name, url)
```


```python
def scrape_news_list_page(response):
    urls = {}
    #print(response.content)
    root = fromstring(response.content)
    #print(root)

    for a in root.xpath('//ul[@class="basic1"]/li/dl/dt/a[@class="_nclicks:kin.txt _searchListTitleAnchor"]'):
        #print(a)
        #print(tostring(a, pretty_print = True))
        name, url = extract_conents(a)    
        urls[name] = url
    return urls
```


```python
def extract_conents(doc):
    link = doc.get("href")
    name = doc.text_content()
    return name, link
```


```python
# 스크랩핑 시작
if __name__ == '__main__':
    main()
```

<pre>
플라스크에서 파이썬 실행 https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=436285489&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=1&search_sort=0&spq=0
v파이썬 파이썬 https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=433970253&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=2&search_sort=0&spq=0
파이썬 코딩 질문 https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=433475801&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=3&search_sort=0&spq=0
파이썬 공부방법 공유해주세요.... https://kin.naver.com/qna/detail.naver?d1id=1&dirId=1040105&docId=437004629&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=4&search_sort=0&spq=0
파이썬, 자바? https://kin.naver.com/qna/detail.naver?d1id=4&dirId=40608&docId=435292280&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=5&search_sort=0&spq=0
해킹 파이썬,칼리리눅스 https://kin.naver.com/qna/detail.naver?d1id=1&dirId=11001&docId=436726953&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=6&search_sort=0&spq=0
파이썬 식 좀 알려주세요 https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=434384411&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=7&search_sort=0&spq=0
파이썬 코드 https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=435106645&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=8&search_sort=0&spq=0
요새 파이썬으로 개발하는 이유 https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=424704487&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=9&search_sort=0&spq=0
파이썬 배우면 어떻게 적용할 수 있나요? https://kin.naver.com/qna/detail.naver?d1id=1&dirId=10402&docId=436900383&qb=7YyM7J207I2s&enc=utf8&section=kin&rank=10&search_sort=0&spq=0
</pre>
## 4. lxml_실습



```python
import requests
import lxml.html

response = requests.get('http://www.hanbit.co.kr/store/books/new_book_list.html')
root = lxml.html.fromstring(response.content)

for a in root.cssselect('.view_box a'):
    url = a.get('href')
    print(url)
```

<pre>
/store/books/look.php?p_code=B5351150617
/store/books/look.php?p_code=B5351150617
/store/books/look.php?p_code=B4422381134
javascript:;
/store/books/look.php?p_code=B4422381134
/store/books/look.php?p_code=B1068448075
javascript:;
/store/books/look.php?p_code=B1068448075
/store/books/look.php?p_code=B9480318629
javascript:;
/store/books/look.php?p_code=B9480318629
/store/books/look.php?p_code=B2079064069
javascript:;
/store/books/look.php?p_code=B2079064069
/store/books/look.php?p_code=B7099909363
/store/books/look.php?p_code=B7099909363
/store/books/look.php?p_code=B5620881464
/store/books/look.php?p_code=B5620881464
/store/books/look.php?p_code=B1398618081
javascript:;
/store/books/look.php?p_code=B1398618081
/store/books/look.php?p_code=B1147715738
javascript:;
/store/books/look.php?p_code=B1147715738
/store/books/look.php?p_code=B3384919392
/store/books/look.php?p_code=B3384919392
/store/books/look.php?p_code=B4508124592
javascript:;
/store/books/look.php?p_code=B4508124592
/store/books/look.php?p_code=B3821180873
javascript:;
/store/books/look.php?p_code=B3821180873
/store/books/look.php?p_code=B4435817798
javascript:;
/store/books/look.php?p_code=B4435817798
/store/books/look.php?p_code=B8870109394
/store/books/look.php?p_code=B8870109394
/store/books/look.php?p_code=B4182532903
javascript:;
/store/books/look.php?p_code=B4182532903
/store/books/look.php?p_code=B9458048985
javascript:;
/store/books/look.php?p_code=B9458048985
/store/books/look.php?p_code=B9711663545
javascript:;
/store/books/look.php?p_code=B9711663545
/store/books/look.php?p_code=B1459262097
/store/books/look.php?p_code=B1459262097
/store/books/look.php?p_code=B1666992199
javascript:;
/store/books/look.php?p_code=B1666992199
/store/books/look.php?p_code=B3672807578
/store/books/look.php?p_code=B3672807578
</pre>
